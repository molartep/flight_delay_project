---
title: "Statistical Analysis Plan"
author: "Martin Olarte"
date: "2023-02-16"
output: pdf_document
urlcolor: blue
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = F, message = F)
library(tidyverse)
library(kableExtra)
library(ggplot2)
library(gridExtra)
```

# Administrative Information

## Authorship Information

This statistical analysis will be primarily conducted by Martin Olarte and reviewed by peers as well as an instructional team composed of Dr. Sam Berchuck and Youran Wu.

## Ethical Assurances

All statistical analyses included in an abstract or manuscript will reflect the SAP and no changes will be made to the SAP without discussing with the SAP author.

## Timeframe

-   Submission I: Aims, Introduction, and EDA, is due at 10am EDT on *February 3* .
-   Submission II: Project Methods, Analysis Plan, & Preliminary Results is due at 10am EDT on *March 3*.
-   Submission III: Final Report is due at 10am EDT on *April 6*.
-   Presentation: The project will be presented in class in *April 11* to get feedback and suggestions from classmates.
-   Final revisions of the individual project (a final report and comprehensive response to reviews) are due at 10am EDT on *April 25*.

# Study Overview

## Background/Introduction

The aviation industry is one of the most critical transportation sectors, providing fast and convenient means of travel for people and goods. On-time performance of flights is a critical aspect of the aviation industry that affects the satisfaction of customers and the reputation of the airlines. The aim of this project is to estimate the delays of flights between RDU (Raleigh-Durham International Airport) and MIA (Miami International Airport) using carrier on-time performance data from the Bureau of Transportation Statistics and weather data from NCDC NOAA datasets.

The rationale behind this project is to provide insights into the factors that contribute to flight delays and to develop a model that can predict the delay of flights. This information can be useful for both airlines to plan their operations and for customers to make informed decisions about their travel plans.

## Study Aims

The main aims of the project are:

### Aim 1 {#aim-1}

1)  To develop a model that predicts the delay of flights between RDU and MIA based on historical carrier performance, scheduled departure time, and weather conditions.

### Aim 2 {#aim-2}

2)  To identify the factors that contribute to flight cancellations, such as weather conditions or specific seasonal trends.

## Primary Hypotheses

The primary hypothesis is that harsh weather conditions typically result in longer delay times and cancellations for flights between RDU and MIA.

## Secondary Hypotheses

The secondary hypotheses are that the relationship between flight delay time / cancellation and weather condition may vary depending on:

-   Departure time of day (e.g. early morning vs. night time)
-   Flight date (hinting towards seasonality effects)
-   Airline-specific factors

## Primary Outcome

```{r}
# CANCELLATION CODES
# A-Carrier Caused
# B-Weather
# C-National Aviation System
# D-Security

data.frame(
  "Outcome" = c(
    "Departure Delay",
    "Cancellation Code"
    ),
  "Description" = c(
    "Departure delay (minutes),\ndefined as actual departure time - CRS (Computer Reservation System) departure time",
    "Cancellation codes used by the Bureau of Transportation Statistics (BTS)"
    ),
  "name" = c(
    "DEP_DELAY (carrier.csv)",
    "CANCELLATION_CODE (carrier.csv)"
    ),
  "Specifications" = c(
    "Minutes (continuous and can be negative)",
    "A=Carrier Caused, B=Weather, C=National Aviation System, D=Security")
) %>%
  rename("Variable Name and Source" = name) %>%
  kbl(booktabs = T, linesep = '\\addlinespace \\addlinespace \\addlinespace',
      caption = "Primary Outcomes") %>%
  column_spec(2, width = "5cm") %>%
  column_spec(1, width = "2cm") %>%
  column_spec(4, width = "3cm") %>%
  row_spec(0, bold=TRUE) %>%
  kable_styling(latex_options = c("scale_down", "HOLD_position"))
```

## Additional Variables of Interest

```{r}
data.frame(
  "Variable" = c(
    "Unique Carrier Code",
    "Scheduled Departure Time",
    "Average Wind Speed",
    "Precipitation",
    "Average Temperature",
    "Maximum Temperature",
    "Minimum Temperature",
    "Direction of fastest 2-minute wind",
    "Direction of fastest 5-minute wind",
    "Fastest 2-minute wind speed",
    "Fastest 5-minute wind speed"
    ),
  "Description" = c(
    "Unique carrier code used to identify airlines",
    "CRS (Computer Reservation System) departure time",
    "Average daily wind speed (miles per hour)",
    "Precipitation (inches)",
    "Average temperature (degrees Fahrenheit)",
    "Maximum temperature (degrees Fahrenheit)",
    "Minimum temperature (degrees Fahrenheit)",
    "Direction of fastest 2-minute wind (degrees)",
    "Direction of fastest 5-minute wind (degrees)",
    "Fastest 2-minute wind speed (miles per hour)",
    "Fastest 5-minute wind speed (miles per hour)"
    ),
  "name" = c(
    "OP_UNIQUE_CARRIER (carrier.csv)",
    "CRS_DEP_TIME (carrier.csv)",
    "AWND.<origin or dest> * (weather.csv)",
    "PRCP.<origin or dest> * (weather.csv)",
    "TAVG.<origin or dest> * (weather.csv)",
    "TMAX.<origin or dest> * (weather.csv)",
    "TMIN.<origin or dest> * (weather.csv)",
    "WDF2.<origin or dest> * (weather.csv)",
    "WDF5.<origin or dest> * (weather.csv)",
    "WSF2.<origin or dest> * (weather.csv)",
    "WSF5.<origin or dest> * (weather.csv)"
    ),
  "Specifications" = c(
    "Character",
    "Military time (integer from 0 (midnight) to 2359 (11:59pm))",
    "Miles per hour (double)",
    "Inches (double)",
    "Degrees Fahrenheit (integer)",
    "Degrees Fahrenheit (integer)",
    "Degrees Fahrenheit (integer)",
    "Degrees (integer from 10 to 360 in intervals of 10)",
    "Degrees (integer from 10 to 360 in intervals of 10)",
    "Miles per hour (double)",
    "Miles per hour (double)"
    )
) %>%
  rename("Variable Name and Source" = name) %>%
  kbl(booktabs = T, linesep = "\\addlinespace",
      caption = "Additional Variables of Interest") %>%
  column_spec(2, width = "5cm") %>%
  column_spec(1, width = "2cm") %>%
  column_spec(4, width = "3cm") %>%
  row_spec(0, bold=TRUE) %>%
  kable_styling(latex_options = c("striped", "scale_down", "HOLD_position")) %>%
  add_footnote("\n *Data is available for both origin and destination locations on the same day (e.g. TMAX.origin and TMAX.dest)", notation = "none", escape = F)

```

```{r}
#source: https://www.bts.gov/topics/airlines-and-airports/airline-codes
code_to_airline <- data.frame(
  Code = c("9E", "AA", "DL", "F9", "MQ", "NK", "YX"),
  Airline = c(
    "Endeavor Air Inc.",
    "American Airlines Inc.",
    "Delta Air Lines Inc.",
    "Frontier Airlines Inc.",
    "Envoy Air",
    "Spirit Air Lines",
    "Republic Airways"
  )
) 

code_to_airline %>%
  rename("Unique Carrier Code" = Code) %>%
  kbl(booktabs = T, align = 'c', linesep = "",
      caption = "Carrier Code to Airline Translation") %>%
  kable_styling(latex_options = c("striped", "HOLD_position"))
```

The complete variable encoding documentation for **weather** data can be found [here](https://www.ncei.noaa.gov/pub/data/cdo/documentation/GHCND_documentation.pdf). Similarly, the complete variable encoding documentation for **carrier** data can be found [here](https://www.transtats.bts.gov/TableInfo.asp?gnoyr_VQ=FGJ&QO_fu146_anzr=b0-gvzr&V0s1_b0yB=D).

# Study Population

## Inclusion Criteria

Flight data was downloaded on a monthly basis from January 2020 to November 2022 for the state of North Carolina only (includes arrival and departure data).

## Exclusion Criteria

The time frame was chosen to gather enough data for statistical significance, but at the same time limiting confounding variables around pre-covid commercial flying patterns. Thus, earlier year data (1987-2019) is still available, but not considered for this analysis.

## Study Design

This is an observational study of commercial flights. Each data point represents a flight at a specified date and time, and attached are core weather statistics for the flight day at both origin and destination airports. All available flights between RDU and MIA were selected, but weather information is less reliable due to potential instrumental/human errors, as well as accessibility to certain data points.

## Data Acquisition

The carrier data was gathered from the BTS website directly, on a monthly basis from January 2020 to December 2022 for the state of North Carolina only (includes arrivals and departures). After binding all monthly data together, and filtering for only flights between RDU and MIA, the weather data (collected from the NCDC NOAA) was joined using the corresponding station IDs for both airports. Weather data was joined twice, once for the origin and once for the destination, and appropriate variable renaming was performed to avoid confusion. Next, irrelevant predictors that would not be available at the time of estimation (other response variables like whether the flight was diverted or arrival information) were immediately discarded for the purpose of this analysis.

```{r importData}
#Documentation: https://www.ncei.noaa.gov/pub/data/cdo/documentation/GHCND_documentation.pdf

weather <- read.csv("RawData/weather.csv")

carrier <- read.csv("RawData/T_ONTIME_REPORTING.csv") %>%
    filter((ORIGIN == "RDU" & DEST == "MIA") | (ORIGIN == "MIA" & DEST == "RDU"))

for (i in 2:24) {
  carrier_i <- read.csv(paste0("RawData/T_ONTIME_REPORTING ", i,".csv")) %>%
    filter((ORIGIN == "RDU" & DEST == "MIA") | (ORIGIN == "MIA" & DEST == "RDU"))
  carrier <- rbind(carrier, carrier_i)
}

# https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00012839/detail
weather$STATION[weather$STATION == "USW00012839"] <- "MIA"

# https://www.ncdc.noaa.gov/cdo-web/datasets/GHCND/stations/GHCND:USW00013722/detail
weather$STATION[weather$STATION == "USW00013722"] <- "RDU"

weather_mia_rdu <- weather %>%
  filter(STATION %in% c("MIA", "RDU")) %>%
  mutate(DATE = as.Date(DATE))

carrier <- carrier %>%
  mutate(FL_DATE = as.Date(FL_DATE, "%m/%d/%Y"))

df <- left_join(carrier, weather_mia_rdu, by = c("ORIGIN" = "STATION", "FL_DATE" = "DATE"))
df <- left_join(df, weather_mia_rdu, by = c("DEST" = "STATION", "FL_DATE" = "DATE"))

df <- df %>%
  select_all(~gsub(".x", ".origin", .)) %>%
  select_all(~gsub(".y", ".dest", .))

df <- df %>%
  select(-c(DEP_TIME, TAXI_OUT, WHEELS_OFF, WHEELS_ON, TAXI_IN, CRS_ARR_TIME, ARR_TIME, ARR_DELAY, CRS_ELAPSED_TIME, ACTUAL_ELAPSED_TIME, CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY, LATE_AIRCRAFT_DELAY, CANCELLED))

```

After data wrangling, variable selection began by determining NA percentages within each column (see the histogram below). The table below shows only numerical columns with more than 70% of observations with their respective summary statistics. Some of the weather data was extremely rare, making it difficult to implement in model fitting, and other data was insignificant (e.g. snowing patterns since it has barely ever snowed at the airport locations).

```{r fig.width=3, fig.height=1.5, fig.cap="Columns NA Percentage"}
df_num <- df %>%
  dplyr::select_if(is.numeric) %>%
  dplyr::select(!contains("dest"))

df_summ <- data.frame(min = sapply(df_num, min, na.rm = TRUE),
                      first_quartile = sapply(df_num, function(x) quantile(x, probs = 0.25, na.rm = TRUE)),
                      median = sapply(df_num, median, na.rm = TRUE),
                      mean = sapply(df_num, mean, na.rm = TRUE),
                      third_quartile = sapply(df_num, function(x) quantile(x, probs = 0.75, na.rm = TRUE)),
                      max = sapply(df_num, max, na.rm = TRUE),
                      percent_NA = sapply(df_num, function(x) sum(is.na(x))/length(x)*100))

df_summ %>%
  ggplot(aes(x = percent_NA)) +
  geom_histogram() +
  xlab("NA Percentage (%)") + 
  ylab("Num. of Columns") +
  theme(axis.title.y = element_text(size=8))
```


``` {r}
df_summ_70 <- df_summ %>%
  filter(percent_NA < 30)

kbl(df_summ_70, row.names = T, digits = 3, booktabs = T, col.names = c("Minimum", "1Q", "Median", "Mean", "3Q", "Maximum", "Percent NA (%)"), caption = "Column Summary Statistics") %>%
  row_spec(0, bold=TRUE) %>%
  kable_styling(latex_options = c("striped", "HOLD_position"))


df <- df %>%
  dplyr::select(-c(PGTM.origin, WDMV.origin, WESD.origin, WESF.origin, WT01.origin, WT02.origin, WT03.origin, WT04.origin, WT05.origin, WT08.origin, WT09.origin, WT10.origin, WT11.origin,
            PGTM.dest, WDMV.dest, WESD.dest, WESF.dest, WT01.dest, WT02.dest, WT03.dest, WT04.dest, WT05.dest, WT08.dest, WT09.dest, WT10.dest, WT11.dest))
```

-   Contact information for data collection/acquisition: Martin Olarte ([mo144\@duke.edu](mailto:mo144@duke.edu){.email})

-   Carrier data was downloaded from the [BTS website](https://www.transtats.bts.gov/DL_SelectFields.aspx?gnoyr_VQ=FGJ&QO_fu146_anzr=b0-gvzr) directly on February 10, 2023.

-   The raw carrier data is stored in `RawData` as monthly csv files and the combined and clean carrier data is available in `Data\carrier.csv`.

-   Weather data was ordered from the [NOAA website](https://www.ncei.noaa.gov/cdo-web/orders?email=mo144@duke.edu&id=3229059) on February 9, 2023 and downloaded after the order was processed.

-   The raw weather data is stored in `RawData\weather.csv` and the clean weather data is available in `Data\weather.csv`.

# Analysis Plans

## Analysis Plan for Aim 1

[Aim 1](#aim-1) will be addressed in the framework of a T-student robust linear model. First, instead of the traditional Ordinary Least Squares (OLS) method for reducing the residuals, robust regression uses different estimators (M-estimators, MM-estimators, etc.) that essentially adjust the weight of each point in an iterative process. Thus, such estimation is much less sensitive to outliers than OLS. This is particularly useful in the context of this aim, since the response variable of interest (Departure Delay) has a great number of outlying values. Furthermore, the T-student distribution has a heavy tail to accommodate outlying errors. This model will be fit in R software using the `rlm()` (robust linear model) function from the MASS package on only the data from January 2020 to December 2021. As noted in an [article](https://www.biostat.jhsph.edu/~iruczins/teaching/jf/ch13.pdf) provided by Johns Hopkins Bloomberg School of Public Health, "the $R^2$ and F-statistics are not given because they cannot be calculated (at least not in the same way)", so "the bootstrap is a general purpose inferential method which is useful in these situations". Similarly, Wilcox et.al also suggest that "percentile bootstrap methods can be used to test hypotheses, which control Type I error probabilities relatively well even when there is heteroscedasticity" [@r.wilcox2013]. In order to evaluate the hypotheses, we will examine the bootsrap distribution of coefficient estimates, with 95% confidence intervals not containing 0 considered evidence of a significant effect. Moreover, interaction terms will be explored using residuals to evaluate model fit too, along with external validation using data from 2022. We will conduct a sensitivity analysis on airport-segregated data by fitting two individual models for RDU and MIA to determine if there are any airport-specific variations. A second sensitivity analysis will focus exclusively on estimating flight delays after the peak of the COVID-19 pandemic by fitting a model solely on data after April 18, 2022 when a federal judge in Florida struck down the U.S. federal transportation mask mandate and all of the major U.S. airlines lifted their pandemic-era mask requirements for domestic flights. The motivation for this being that the pandemic clearly had an effect on the transportation sector, which could be confounding some of the results of delays during periods where passengers were required to wear a face mask and airlines had to go through an additional step of checking this requirement. Finally, time permitting, we will address issues of generalizability of the data via exploratory analysis incorporating available data from other airports.

## Analysis Plan for Aim 2

[Aim 2](#aim-2) will rely on a logistic regression model to identify the factors that contribute to flight cancellations due to weather. The response variable Cancellation Code is categorical, but we are only interested in weather-related cancellations (Code C), since the other types of cancellations are much more rare and have a sparse nature that makes it difficult to model (e.g. a national security alert). Thus, we can remove such records and the response can be converted to binary, where 1 represents flights cancelled due to weather and 0 represents any other flight that was not cancelled. The logistic regression model will be fit in R software, using the `glm()` function with a binomial family. To identify the most important predictors in the model, we will conduct a variable selection procedure such as stepwise selection or LASSO regularization using AIC and BIC as information criteria to decide whether to include a predictor or not. If AIC and BIC do not agree, further investigation would be required to determine if that predictor should be included, always erring on the side of interpretability. During model fitting, assumptions must be checked. Absence of multicollinearity will be assessed with the `vif()` function from the `car` package, residual plots will be used to check for linearity and homoscedasticity assumptions, and the normality of residuals will be checked via a normal probability plot using the `qqnorm()` and `qqline()` functions. To evaluate the fit of the model, we will use standard goodness-of-fit measures, such as the Hosmer-Lemeshow test to compare the observed and expected frequencies in groups defined by the predicted probabilities, and the receiver operating characteristic (ROC) curve. We will calculate the area under the ROC curve (AUC) to quantify the discrimination ability of the model. To measure the predictive power of the model, we will also use 10-fold cross-validation due to the size of the dataset. Coefficient interpretation will be crucial to identify the factors that contribute most strongly to flight cancellations. We will calculate odds ratios and their confidence intervals to quantify the effect size of each predictor, summarizing the results in a table with visualizations for where the odd ratio of each coefficient stands to determine statistical and practical significance. All 95% confidence intervals not containing 0 considered evidence of a significant effect. Sensitivity analyses will test the robustness of the model, including the segregation of airport data like in Aim 1, but also segregation of airline data. Also, the use of alternative model specifications, such as different forms of the predictors (linear vs. quadratic) and their effect on the model can be explored. The generalizability of the findings for this aim could be hindered considering the potential impact of external factors (such as natural disasters) on flight cancellations. Moreover, the number of cancelled flights in the current dataset could be too small for a powerful analysis, and could call for older data which would not be confounded by the Covid-19 pandemic as much since the aim is limited to weather-related cancellations.

# Exploratory Analyses

```{r plots_eda, fig.height=3, fig.width=10, fig.cap="Response Variable EDA"}
# 127 / 7,859 observations are above 3 hrs (180 min) delay
df_no_outliers <- df %>%
  filter(DEP_DELAY < 180)

ggplot_carrier <- ggplot(df_no_outliers, aes(x=OP_UNIQUE_CARRIER, y=DEP_DELAY)) +
  geom_violin() +
  geom_boxplot(width = 0.1) +
  ggtitle("Departure Delay by Carrier") +
  xlab("Carrier Code") + 
  ylab("Departure Delay (min)") +
  theme(axis.title.y = element_text(size=10))

ggplot_dep_time <- ggplot(df_no_outliers, aes(x=CRS_DEP_TIME, y=DEP_DELAY)) +
  geom_point(aes(alpha = 0.05)) +
  ggtitle("Departure Delay vs Departure Time") +
  theme(legend.position = "none") +
  xlab("Departure Time (Military Time)") + 
  ylab("Departure Delay (min)") +
  theme(axis.title.y = element_text(size=10))

vars <- colnames(df_no_outliers)
vars <- vars[!vars %in% c("FL_DATE", "OP_UNIQUE_CARRIER", "ORIGIN", "DEST", "CRS_DEP_TIME", "DEP_DELAY", "DIVERTED")]
for (variable in vars) {
  plot_var_name <- str_c(c("ggplot", variable), collapse = "_")
  temp_plot <- ggplot(df_no_outliers, aes_string(x=variable, y="DEP_DELAY")) +
    geom_point(aes(alpha=0.05), na.rm = T) +
    theme(legend.position = "none") +
    ylab("Departure Delay (min)")
  assign(plot_var_name, temp_plot)
}
grid.arrange(
  ggplot_carrier,
  ggplot_dep_time, ncol = 2
)
```

The plots shown below from Figure 3 and 4 are limited to data with a departure delay less than 3 hours or 180 minutes. Only 127 out of the total 7,859 flight observations have departure delays above 3 hours, which is only 1.62% of the data. Thus, it seemed reasonable to fit a model with a heavy-tailed distribution for the error terms. All carriers seem to have a similar highly skewed distribution of delay times, with center around 0 and a long tail towards longer delay times. However, there are differences in variance for outlying values particularly because 4,093 out of the 7,859 flights are from American Airlines. This further motivates the sensitivity analysis with respect to airline segregation for delays and cancellations.

```{r plots, fig.height=7, fig.width=8.5, fig.cap="Predictors vs Response Variable (See Table 2 for variable names)"}
grid.arrange(
  ggplot_AWND.origin,
  ggplot_AWND.dest,
  ggplot_PRCP.origin,
  ggplot_PRCP.dest,
  ggplot_TAVG.origin,
  ggplot_TAVG.dest,
  ggplot_WSF5.origin,
  ggplot_WSF5.dest, ncol = 2
)

AA_df <- df %>%
  filter(OP_UNIQUE_CARRIER == "AA")
```

From the EDA, it is evident that pairs of weather covariates from the destination and origin will be highly correlated due to the fact that measurements are daily summaries, which could be an issue looking forward but will be decided when addressing multicollinearity. 

```{r timeplots, fig.height=4, fig.width=10, fig.cap="Time Series Plots"}

myMtime <- df$CRS_DEP_TIME
date <- df$FL_DATE
myMtime <- sprintf("%04d", myMtime)
df$date_time <- as.POSIXct(paste0(date, " ", myMtime), format = "%Y-%m-%d %H%M", origin = "1970-01-01", tz = "EST")

all_time <- df %>%
  ggplot(aes(x = date_time, y = DEP_DELAY)) + 
  geom_line() +
  geom_smooth() +
  xlab("Flight Date") + 
  ylab("Departure Delay (min)") +
  theme(axis.title.y = element_text(size=8))
onehr_time <- df %>%
  filter(DEP_DELAY < 60) %>%
  ggplot(aes(x = date_time, y = DEP_DELAY)) + 
  geom_line() +
  geom_smooth() +
  xlab("Flight Date") + 
  ylab("Departure Delay") +
  theme(axis.title.y = element_text(size=8))

grid.arrange(
  all_time,
  onehr_time, ncol = 1
)
```

From the time series data in Figure 5, which could be interesting to explore further to identify seasonal or weekly changes, we can see that the outlying values are dominating the dataset, and even when filtering extremely for delays of less than 1 hour, fitting the default cubic spline GAM does not indicate any significant trend initially.

```{r cancellations, fig.height=2, fig.width=10, fig.cap="Flight Cancellations"}
df <- df %>%
  mutate(CANCELLED_WEATHER = if_else(CANCELLATION_CODE == "C", "1", "0")) 

df %>%
  ggplot(aes(x = FL_DATE, y = TMAX.origin, group = CANCELLED_WEATHER)) +
  geom_point(aes(shape=CANCELLED_WEATHER, color=CANCELLED_WEATHER, size=CANCELLED_WEATHER, alpha = CANCELLED_WEATHER)) +
  xlab("Flight Date") + 
  ylab("Minimum Temperature at Origin (Fahrenheit)") +
  theme(axis.title.y = element_text(size=8), legend.position = "none")

df %>%
  ggplot(aes(x = TAVG.origin, y = PRCP.origin, group = CANCELLED_WEATHER)) +
  geom_point(aes(shape=CANCELLED_WEATHER, color=CANCELLED_WEATHER, size=CANCELLED_WEATHER, alpha = CANCELLED_WEATHER)) +
  xlab("Average Temperature at Origin (Fahrenheit)") + 
  ylab("Precipitation at Origin (Inches)") +
  theme(axis.title.y = element_text(size=8), legend.position = "none")

```

Finally, regarding flight cancellation trends, there were a total of 172 cancelled flights in the dataset, and only 17 of those were weather related (Code C). From Figure 6 it is evident that the cancelled flights due to weather (represented by blue triangles) were only present after 2022 in the data, and there seems to be a correlation with temperature. However, precipitation is not seen as a particularly strong predictor as expected.

# Software

-   R version 4.2.2 (2022-10-31) using the tidyverse, ggplot2, gridExtra, MASS, and car packages, along with their dependencies.

# References

